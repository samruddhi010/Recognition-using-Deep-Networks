{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODLEieN3bjasSVrJwxXeXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pheonix10101/PRCV_p_5/blob/main/new_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Project 5: Recognition using Deep Networks\n",
        "\n",
        "Author: Samruddhi Raut\n",
        "\n",
        "This file contain following tasks\n",
        "Task 1\n",
        "F: Test the network on new inputs\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.io import read_image\n",
        "from matplotlib import pyplot as plt\n",
        "import CNN\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "class NumDraw_data(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform = None, target_transform = None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path).float()\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    loaded_net = CNN.NeuralNetwork()\n",
        "    loaded_net_state_dict = torch.load('samruddhi_neural.pt')\n",
        "    loaded_net.load_state_dict(loaded_net_state_dict)\n",
        "\n",
        "    hand_write_dateset = NumDraw_data(annotations_file = '/content/num_drawn_dataset.csv',\n",
        "                                          img_dir = '/content/num_drawn_dataset')\n",
        "    hand_write_dataloader = DataLoader(dataset = hand_write_dateset,\n",
        "                                       batch_size = CNN.BATCH_SIZE_TEST,\n",
        "                                       shuffle = False,\n",
        "                                       num_workers = 4)\n",
        "\n",
        "    # set model to evalution mode\n",
        "    loaded_net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    imgs = []\n",
        "    predictions = []\n",
        "   \n",
        "    with torch.no_grad(): # disable gradient calculation is useful for inference, backward() will not be called in testing\n",
        "        for data, target in hand_write_dataloader:\n",
        "            output = loaded_net(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction = 'sum').item()\n",
        "            pred = output.data.max(1, keepdim = True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            imgs.append(data)\n",
        "            predictions.append(pred)\n",
        "\n",
        "    \n",
        "    set_len = len(hand_write_dataloader.dataset)# noinspection PyTypeChecker\n",
        "   \n",
        "    if (set_len / CNN.BATCH_SIZE_TEST).is_integer():\n",
        "        batch_num = set_len / CNN.BATCH_SIZE_TEST\n",
        "    else:\n",
        "        batch_num = int(set_len / CNN.BATCH_SIZE_TEST) + 1\n",
        "    test_loss /= set_len\n",
        "\n",
        "    print('\\nTest over handwrite test set: Avg.loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss, correct, set_len, 100. * correct / set_len))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    i = 0\n",
        "    c = 0\n",
        "    while i < batch_num:\n",
        "        for j in range(CNN.BATCH_SIZE_TEST):\n",
        "            if c >= set_len:\n",
        "                i = batch_num\n",
        "                break\n",
        "            plt.subplot(4, 3, c + 1)\n",
        "            plt.tight_layout()\n",
        "            plt.imshow(imgs[i][j][0], cmap = 'gray', interpolation = 'none')\n",
        "            plt.title(\"Prediction: %d\" % predictions[i][j])\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            c += 1\n",
        "        i += 1\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "c3l0uMV5mFox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}